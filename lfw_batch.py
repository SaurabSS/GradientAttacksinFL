# -*- coding: utf-8 -*-
"""LFW_batch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iYTF2ECH6o4SfoDVDc8_6d6x1NcQSTFL
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import numpy as np
from pprint import pprint

from PIL import Image
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import grad
import torchvision
from torchvision import models, datasets, transforms
import torch.nn.functional as func
#torch.manual_seed(50)




print(torch.__version__, torchvision.__version__)

print (torch.cuda.get_device_name(device='cuda:0'))

!nvidia-smi -L
!nvidia-smi
!lscpu |grep 'Model name'
!lscpu | grep "MHz"
!free -h --si | awk  '/Mem:/{print $2}'
!df -h / | awk '{print $4}'
def get_colab_usage(pip_install=False, import_libs=True, return_fn=True):
    """ Retrieve Google Colab Resource Utilization Stats
    
    Args:
        pip_install (bool, optional): Whether to preform pip installs
        import_libs (bool, optional): Whether to import libraries
        return_fn (bool, optional): Whether or not to return get_usage fn
    
    Returns:
        The get_usage fn ...
            (potentially... only if return_fn flag is set to True)
            ... which can be used to determine resource utilization stats
            at any time in the future of this session without need for
            any pip installs or library imports or fn definitions
    """
    
    # if pip_install:
    #     # memory footprint support libraries/code
    #     !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
    #     !pip install gputil
    #     !pip install psutil
    #     !pip install humanize

    if import_libs:
        import psutil
        import humanize
        import os
        import GPUtil as GPU

    def print_resource_usage():
        """Function that actually retrieves resource utilization statistics"""   
        
        # Get the activate GPU
        # TODO >>> GPU not guaranteed to be the only one <<< TODO
        gpu = GPU.getGPUs()[0]

        # Get current process
        process = psutil.Process(os.getpid())

        # Get general ram usage
        gen_ram = humanize.naturalsize(psutil.virtual_memory().available)

        # Get processor size
        proc_size = humanize.naturalsize(process.memory_info().rss)

        # Get gpu stats
        gpu_free_mem  = gpu.memoryFree
        gpu_used_mem  = gpu.memoryUsed
        gpu_util_mem  = gpu.memoryUtil*100
        gpu_total_mem = gpu.memoryTotal

        # Print interpretable resource utilization statistics
        print("\n------------------------------------------------------")
        print("             RESOURCE USAGE STATISTICS                ")
        print("------------------------------------------------------\n")
        print("Gen RAM Free: {:8} | " \
              "Proc size   : {}"\
              "".format(gen_ram, proc_size)) 
        
        print("GPU RAM Free: {:4.0f} MB | " \
              "Used        : {:5.0f} MB | " \
              "Util        : {:5.0f}% | " \
              "Total       : {:5.0f}MB\n" \
              "".format(gpu_free_mem, gpu_used_mem, 
                        gpu_util_mem, gpu_total_mem))

    # Internally call the fn
    print_resource_usage()

    if return_fn:
        return(print_resource_usage)

# This will print the resource utilization and give us access
# to the fn `get_usage` which can now be called like a regular
# function with no arguments required.
get_usage = get_colab_usage(pip_install=True, return_fn=True)

# dst = datasets.CIFAR100("~/.torch", download=True)
# dst = datasets.MNIST("~/.torch", download=True)

tp = transforms.Compose([
    transforms.Resize(32),
    transforms.CenterCrop(32),
    transforms.ToTensor()
])
tt = transforms.ToPILImage()

device = "cpu"
if torch.cuda.is_available():
    device = "cuda"
print("Running on %s" % device)

def label_to_onehot(target, num_classes=10):
    target = torch.unsqueeze(target, 1)
    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)
    onehot_target.scatter_(1, target, 1)
    return onehot_target

def cross_entropy_for_onehot(pred, target):
    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))

# def weights_init(m):
#     if hasattr(m, "weight"):
#         m.weight.data.uniform_(-0.5, 0.5)
#         nn.init.xavier_uniform_(m.weight.data)
#     if hasattr(m, "bias"):
#         #m.bias.data.uniform_(
    # -0.5, 0.5)
#         #nn.init.xavier_uniform(m.bias.data)
#         m.bias.data.fill_(0)



# class LeNet(nn.Module):

#     def __init__(self):

#         super(LeNet, self).__init__()
#         self.conv1 = nn.Conv2d(3, 6, kernel_size=5,stride=2)
#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=2)
#         self.fc1 = nn.Linear(16*5*5, 256)
#         self.fc2 = nn.Linear(256, 120)
#         self.fc3 = nn.Linear(120, 106)

#     def forward(self, x):
#         #x = func.relu(self.conv1(x))
#         x = func.sigmoid(self.conv1(x))
#         #x = func.max_pool2d(x, 2)
#         #x = func.relu(self.conv2(x))
#         x = func.sigmoid(self.conv2(x))
#         #x = func.max_pool2d(x, 2)
#         x = x.view(x.size(0), -1)
#         #x = func.relu(self.fc1(x))
#         x = func.sigmoid(self.fc1(x))
#         #x = func.relu(self.fc2(x))
#         x = func.sigmoid(self.fc2(x))
#         x = self.fc3(x)
#         return x

    
    
# def weights_init(m):
#     if hasattr(m, "weight"):
#         m.weight.data.uniform_(-0.3, 0.3)
#     if hasattr(m, "bias"):
#         m.bias.data.uniform_(-0.3, 0.3)

torch.manual_seed(50)

def weights_init(m):
    if hasattr(m, "weight"):
        m.weight.data.uniform_(-0.5, 0.5)
    if hasattr(m, "bias"):
        m.bias.data.uniform_(-0.5, 0.5)
        
def weights_init_dropout(m):
    if hasattr(m, "weight"):
        m.weight.data.uniform_(-0.1, 0.1)
    if hasattr(m, "bias"):
        m.bias.data.uniform_(-0.1, 0.1)

class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        act = nn.Sigmoid
        #act = nn.Tanh
        #act = nn.ReLU
        self.body = nn.Sequential(
            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),
            act(),
            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),
            act(),
            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),
            act(),
            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),
            act(),
        )
        self.fc = nn.Sequential(
                nn.Linear(768, 106)
                 #nn.Dropout(p=0.01)
        )
        
    def forward(self, x):
        out = self.body(x)
        out = out.view(out.size(0), -1)
        # print(out.size())
        out = self.fc(out)
        return out

    

net = LeNet().to(device)
net.apply(weights_init)


# class LeNet_att(nn.Module):
#     def __init__(self):
#         super(LeNet_att, self).__init__()
#         act = nn.Sigmoid
#         #act = nn.Tanh
#         #act = nn.ReLU
#         self.body = nn.Sequential(
#             nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),
#             act(),
#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),
#             act(),
#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),
#             act(),
#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),
#             act(),
#         )
#         self.fc = nn.Sequential(
#                 nn.Linear(768, 106)
#         )
        
#     def forward(self, x):
#         out = self.body(x)
#         out = out.view(out.size(0), -1)
#         # print(out.size())
#         out = self.fc(out)
#         return out

# net_att = LeNet_att().to(device)
# net_att.apply(weights_init_dropout)
    
#criterion = cross_entropy_for_onehot
criterion = nn.CrossEntropyLoss()

import torchvision.transforms as transforms
import torch.optim as optim
from torch.autograd import Variable
from torch.utils import data

from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
lfw_people=fetch_lfw_people(min_faces_per_person=40,color=True,slice_=(slice(61,189),slice(61,189)),resize=0.25)
x=lfw_people.images
y=lfw_people.target

target_names=lfw_people.target_names
n_classes=target_names.shape[0]

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,shuffle=False)


# #two people
# X_train_two = []
# y_train_two = []
# X_test_two = []
# y_test_two = []
# for ct_d in range(X_train.shape[0]):
#     if  y_train[ct_d] == 6:
#         X_train_two.append(X_train[ct_d])
#         y_train_two.append(0)
#     if  y_train[ct_d] == 9:
#         X_train_two.append(X_train[ct_d])
#         y_train_two.append(1)
        
# for ct_d in range(X_test.shape[0]):
#     if  y_train[ct_d] == 6:        
#         X_test_two.append(X_test[ct_d])
#         y_test_two.append(0)
#     if  y_train[ct_d] == 9:
#         X_test_two.append(X_test[ct_d])
#         y_test_two.append(1)
        
# X_train = np.asarray(X_train_two)    
# X_test = np.asarray(X_test_two)  
# y_train = np.asarray(y_train_two)  
# y_test = np.asarray(y_test_two)  

print (X_train.shape)
print (X_test.shape)

         
X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)
X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)
#X_train = torch.transpose
#X_train = X_train.astype('float32')
X_train /= 255.0
X_test /= 255.0


print (X_train.shape)
print (X_test.shape)


x_train = torch.FloatTensor(X_train).to(device)
x_train = x_train.transpose(2,3).transpose(1,2)
y_train = torch.LongTensor(y_train).to(device)

x_test = torch.FloatTensor(X_test).to(device)
x_test = x_test.transpose(2,3).transpose(1,2)
y_test = torch.LongTensor(y_test).to(device)


training = data.TensorDataset(x_train,y_train)

testing = data.TensorDataset(x_test,y_test)

dst_tensor=training

criterion_train = nn.CrossEntropyLoss()
optimizer_train = optim.Adam(net.parameters(),lr=0.01)#,momentum=0.9)
trainloader = torch.utils.data.DataLoader(training,batch_size=32, shuffle=True)

for i,data in enumerate(trainloader,0):
  # print(i)
  if i==1:
    print(len(data))
    print(len(data[0]))
    print((data[1]))

iter_ = 0
client_iters = 0
batch = 1

for epoch in range(1):

    for i,data in enumerate(trainloader,0):
   
        #if epoch>=1:
        if iter_<=client_iters:
            print("client iteration complete")
            #break
            iter_=iter_+1
            #print (iter_)
            inputs,label = data

            inputs,label =  Variable(inputs),Variable(label) 

            optimizer_train.zero_grad()


            outputs_benign=net(inputs)
            #outputs_benign = F.softmax(outputs_benign, dim=-1)
            #print (outputs_benign[0])


            loss_benign =  criterion_train(outputs_benign,label)

            #print("loss computed")
            loss_benign.backward()
            #print("loss BP")
            optimizer_train.step()

            #if i%2000==0:
            print (loss_benign.item())
            #torch.save(net.state_dict(),'./LFW_net.pth')  
       
  
print ('fininshed training')
total = len(y_test)
acc =0.0
for ct in range(total):
    testing_data = tt(testing[ct][0].cpu())
    testing_data1 = tp(testing_data).to(device)
    testing_data2 = testing_data1.view(1, *testing_data1.size())
    y_pred = net(testing_data2)
    predicted = torch.argmax(y_pred)
  
    if predicted == y_test[ct]:
        acc=acc+1
accuracy = acc / total
print (accuracy)
print ('fininshed testing')

######### honest participant #########
img_index = 2   #use img_index
dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index

gt_data = tp(dst_pil).to(device)
gt_data = torch.unsqueeze(gt_data,0)

gt_label = dst_tensor[img_index][1].long().to(device) #use img_index
gt_label = gt_label.view(1, )
gt_onehot_label = label_to_onehot(gt_label, num_classes=106)

plt.imshow(dst_pil)
plt.axis('off')
plt.savefig("./lfw_batch_idx_12")

print(gt_label)


#idx_m = [20,25,32,33,48,79,84]
#idx_m = [2]
idx_m = []
match = 1
for s in range(1000):
    if dst_tensor[s][1]==4:
        if match<4:
            match = match + 1
        else:    
          idx_m.append(s)
        
        dst_pil = tt(dst_tensor[s][0].cpu())
        plt.imshow(dst_pil)
        plt.axis('off')
        #plt.savefig("./original/lfw_batch_idx_%s"%(len(idx_m)))
        
        
        if len(idx_m)==batch:
            break
print("idx is below")
print (idx_m)
            
for bat in range(batch-1):
            dst_pil = tt(dst_tensor[idx_m[bat+1]][0].cpu())   #use img_index
            tmp = torch.unsqueeze(tp(dst_pil).to(device),0)
            #print(tmp.shape)
            gt_data = torch.cat((gt_data,tmp),0)

            gt_label_tmp = dst_tensor[idx_m[bat+1]][1].long().to(device) #use img_index
            gt_label_tmp = gt_label_tmp.view(1, )
            gt_label = torch.cat((gt_label,gt_label_tmp),0)
            gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=106)),0)

    #plt.imshow(dst_pil)
    #plt.axis('off')
    #plt.savefig("./original/lfw_batch_idx_%s"%(idx_m[bat]))
    
    #plt.title("Ground truth image")
    #print("GT label is %d." % gt_label.item(), "\nOnehot label is %d." % torch.argmax(gt_onehot_label, dim=-1).item())

    
gt_label = torch.reshape(gt_label,(-1,1))    
print (gt_data.shape)
print (gt_label.shape)
print (gt_onehot_label.shape)
print (gt_label)


# compute original gradient 
dy_dx = []
original_dy_dx=[]
original_pred = []
# for item in range(batch):
#     gt_data_single = torch.unsqueeze(gt_data[item],0)
#     out = net(gt_data_single)
#     #y = criterion(out, gt_onehot_label[item])
#     y = criterion(out, gt_label[item])
#     dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)
#     original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))
#     original_dy_dx.append(original_dy_dx_tmp)
#     out_tmp = out.detach().clone()
#     original_pred.append(out_tmp)
    
    

out = net(gt_data)
#y = criterion(out, gt_onehot_label[item])
gt_label_batch = torch.squeeze(gt_label,dim=1)
y = criterion(out, gt_label_batch)
dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)
original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))
print(len(dy_dx))
original_dy_dx.append(original_dy_dx_tmp)
out_tmp = out.detach().clone()
original_pred.append(out_tmp)

    #dy_dx.append(torch.autograd.grad(y, net.parameters()))

    
    
# #FOR fully-connected model only
#     dw = net.body[0].weight
#     db = net.body[0].bias
#     dy_dw = torch.autograd.grad(y, dw,retain_graph=True)
#     dy_db = torch.autograd.grad(y, db,retain_graph=True)

#     print (dy_dw)
#     #print (dy_db.shape)

#     leak=dy_dw/dy_db

#     print (leak.shape)
    


# share the gradients with other clients
#original_dy_dx = list((_.detach().clone() for _ in dy_dx))
print(len(original_dy_dx))

#!pip install pytorch_msssim

# generate dummy data and label
import time
import torch.nn.functional as F
from pytorch_msssim import ssim


#print (ssim(0.43*torch.unsqueeze(gt_data[0],dim=0),torch.unsqueeze(gt_data[0],dim=0),data_range=0).item())
#print (torch.dist(0.6*torch.unsqueeze(gt_data[0],dim=0),torch.unsqueeze(gt_data[0],dim=0),2).item())

mses = []
ssims = []

for item in range(1):
    start = time.clock()
    for rd in range(1):

        torch.manual_seed(100*rd+9)
        # dummy_data = torch.unsqueeze(torch.randn(gt_data[item].size()),0).to(device).requires_grad_(True)
        
        # dummy_data = torch.unsqueeze(torch.zeros(gt_data[item].size()),0).to(device).requires_grad_(True)
        #dummy_data = torch.unsqueeze(torch.ones(gt_data[item].size()),0).to(device).requires_grad_(True)

        
        #background = torch.unsqueeze(torch.zeros(gt_data[item].size()),0)
        #background[0,2,::] = 1
        #dummy_data = background.to(device).requires_grad_(True)
        #dummy_data = (torch.unsqueeze(torch.randn(gt_data[item].size()),0)+background).to(device).requires_grad_(True)
        
        #surrogate = torch.unsqueeze(gt_data[item+1],0)
        #aaa = torch.rand([3,16,16])
        #surrogate[0,:,8:24,8:24] =aaa
        #dummy_data = surrogate.to(device).requires_grad_(True)    
        
        #dummy_data = torch.unsqueeze(gt_data[item+1],0).to(device).requires_grad_(True)
        
        #k = np.random.randint(0,95)
        #dummy_data = torch.unsqueeze(gt_data[k],0).to(device).requires_grad_(True)
        
        
        # pat_1 = torch.rand([3,16,16])
        # pat_2 = torch.cat((pat_1,pat_1),dim=1)
        # pat_4 = torch.cat((pat_2,pat_2),dim=2)
        # dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)
        
        
        #aaa = torch.rand([3,8,8])
        #bbb = torch.cat((aaa,aaa),dim=1)
        #ccc = torch.cat((bbb,bbb),dim=1)
        #ddd = torch.cat((ccc,ccc),dim=2)
        #eee = torch.cat((ddd,ddd),dim=2)
        #dummy_data = torch.unsqueeze(eee,dim=0).to(device).requires_grad_(True)
        
        aaa = torch.rand([3,4,4])
        bbb = torch.cat((aaa,aaa),dim=1)
        ccc = torch.cat((bbb,bbb),dim=1)
        ddd = torch.cat((ccc,ccc),dim=1)
        eee = torch.cat((ddd,ddd),dim=2)
        fff = torch.cat((eee,eee),dim=2)
        ggg = torch.cat((fff,fff),dim=2)
        dummy_data = torch.unsqueeze(ggg,dim=0).to(device).requires_grad_(True)
        
        
        #dummy_data = plt.imread("./attack_image/replacement_69.png")
        #print (dummy_data.shape)
        #dummy_data = torch.FloatTensor(dummy_data).to(device)
        #dummy_data = dummy_data.transpose(2,3).transpose(1,2)
        
        dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)
        
        dummy_label = torch.randn(dummy_unsqueeze.size()).to(device).requires_grad_(True)
        label_pred=torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), 
                                dim=-1).detach().reshape((1,)).requires_grad_(False)
        #print (original_dy_dx[item][-1].shape)
        #print (original_dy_dx[item][-1].argmin())
        
        #print (torch.sum(original_dy_dx[item][-2], dim=-1).argmin())
        
        plt.imshow(tt(dummy_data[0].cpu()))
        plt.title("Dummy data")
        #plt.savefig("./random_seed/index_%s_rand_seed_%s_label_%s"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))

        plt.clf()
        print("Dummy label is %d." % torch.argmax(dummy_label, dim=-1).item())
        print("stolen label is %d." % label_pred.item())
        
        
        #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])
        optimizer = torch.optim.LBFGS([dummy_data,])
        #optimizer = torch.optim.AdamW([dummy_data,],lr=0.01)
      
       

        history = []
        
        percept_dis = np.zeros(300)
        recover_dis = np.zeros(300)
        for iters in range(300):
            
          
            percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()
            recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()
           
            history.append(tt(dummy_data[0].cpu()))
            def closure():
                optimizer.zero_grad()

                pred = net(dummy_data) 
                #dummy_onehot_label = F.softmax(dummy_label, dim=-1).long()
                
                #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.
                #print (pred)
                #print (label_pred)
            
                dummy_loss = criterion(pred, label_pred)
                dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)
                #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)
                #print (dummy_dy_dp[0].shape)  

                grad_diff = 0
                grad_count = 0
                #count =0
                for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here
                   
                    #if iters==500 or iters== 1200:
                    #print (gx[0])
                    #    print ('hahaha')
                    #print (gy[0])
                    lasso = torch.norm(dummy_data,p=1)
                    ridge = torch.norm(dummy_data,p=2)
                    grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge 
                    
                    #print (gx.shape)

                    grad_count += gx.nelement()
                

                    #if count == 9:
                    #    break
                    #count=count+1
                # grad_diff = grad_diff / grad_count * 1000
                
                #grad_diff += ((original_pred[item]-pred)**2).sum()
               
                
                
                
                grad_diff.backward()
                #print (count)

                #print (dummy_dy_dx)
                #print (original_dy_dx)


                return grad_diff



            optimizer.step(closure)
            if iters % 5 == 0: 
                current_loss = closure()
                #if iters == 0: 
                print ("%.8f" % current_loss.item())
                #print(iters, "%.8f" % current_loss.item())
            history.append(tt(dummy_data[0].cpu()))

            mses.append(F.mse_loss(gt_data[0][0, :], dummy_data[0][0, :]))
            print(gt_data[0].size())
            print(dummy_data.size())
            ssims.append(ssim(gt_data[0][None,:],dummy_data[0][None,:],))
        
        #plt.figure(figsize=(18, 12))
        #for i in range(60):
        #  plt.subplot(6, 10, i + 1)
        #  plt.imshow(history[i * 5])
        #  plt.title("iter=%d" % (i * 5))
        #  plt.axis('off')
        
        
        plt.figure(figsize=(9, 1.2))
        iter_idx = [0,10,20,40,50,100,150,200,300]
        for i in range(9):
          plt.subplot(1, 9, i + 1)
          plt.imshow(history[iter_idx[i]])
          plt.title("iter=%d" % (iter_idx[i]))
          plt.axis('off')
            
        #np.savetxt('ssim_random_batch8',percept_dis,fmt="%4f")
        #np.savetxt('mse_random_batch8',recover_dis,fmt="%4f")
        
        #print("Dummy label is %d." % torch.argmax(dummy_label, dim=-1).item())
        
        # plt.savefig("./index_%s_rand_%s_label_%s"%(item,rd, label_pred.item()))
        #plt.clf()
       
    duration = time.clock()-start
    #print ("Running time is %.4f." %(duration/10.0) )
    print (duration/10.0 )

plt.figure(figsize=(9, 1.2))
for i in range(batch):
  plt.subplot(1,batch,i+1)
  plt.imshow(tt(gt_data[i].cpu()))
  plt.axis("off")

iter_idx = [0,10,20,40,50,100,150,200,300]
plt.figure(figsize=(9, 1.2))
for i in range(9):
  plt.subplot(1, 9, i + 1)
  plt.imshow(history[iter_idx[i]])
  plt.title("iter=%d" % (iter_idx[i]))
  plt.axis('off')

# a_list = ["abc", "def", "ghi"]
textfile = open(f"ssimsB{ batch }.txt", "w")
# print(len(ssims))
# print(len(mses))
for element in percept_dis:
    textfile.write(str(element) + "\n")
textfile.close()
textfile = open(f"msesB{ batch }.txt", "w")
for element in recover_dis:
    textfile.write(str(element) + "\n")
textfile.close()

fig = plt.figure()
a1 = fig.add_axes([0,0,1,1])
x = np.arange(1,301)
a1.plot(x,percept_dis)
a1.set_xlabel('Iterations')
a1.set_ylabel('SSIM')
plt.ylim(0,1)
a2 = a1.twinx()
a2.plot(x, mses,'r')
# plt.ylim(0,0.09)
a2.set_ylabel('MSE')
fig.legend(labels = ('SSIM','MSE'),bbox_to_anchor=(1.1, 1),loc='center right')
plt.title(f"SSIM and MSE vs Iters, for B = { batch } and Client Iters = { client_iters }")
plt.show()

plt.figure(figsize=(12, 8))
for i in range(60):
  plt.subplot(6, 10, i + 1)
  plt.imshow(history[i * 5])
  plt.title("iter=%d" % (i * 5))
  plt.axis('off')
print("Dummy label is %d." % torch.argmax(dummy_label, dim=-1).item())

plt.figure(figsize=(12, 8))
for j in range(batch):
    for i in range(60):
      plt.subplot(6, 10, i + 1)
      plt.imshow(history_batch[i * 5+j])
      plt.title("iter=%d" % (i * 5+ j))
      plt.axis('off')
print("Dummy label is %d." % torch.argmax(dummy_label, dim=-1).item())

